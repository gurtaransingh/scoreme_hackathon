{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "109yi_C1Nn__StVPM8HdCTx7Jl4fG-QCX",
      "authorship_tag": "ABX9TyNJYtIgumhnwUQa7KgUgfRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurtaransingh/scoreme_hackathon/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code optimised for Test3 file**"
      ],
      "metadata": {
        "id": "X0UN8Uxqncdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Purpose:\n",
        "This Python script extracts structured data from a PDF file and saves it into an Excel spreadsheet. It utilizes PyMuPDF for PDF handling and pandas for data manipulation.\n",
        "\n",
        "##Features:\n",
        "PDF Parsing: The script reads a specified PDF file (test3.pdf in this case) using PyMuPDF, extracting text from each page.\n",
        "\n",
        "##Data Extraction:\n",
        "\n",
        "**Field and Value Extraction:** It identifies fields and their corresponding values by splitting lines based on colon (:) where possible.\n",
        "\n",
        "**Amount Extraction:** It extracts amounts with decimals and commas from lines using regular expressions.\n",
        "\n",
        "**Amounts with \"Dr\":** It captures amounts followed by \"Dr\" for financial transactions.\n",
        "\n",
        "**Transaction Type:** It identifies transaction types ('C' for Credit, 'T' for Debit) and extracts text following them.\n",
        "\n",
        "**Important Dates:** It captures dates in the format DD-MMM-YYYY from the text.\n",
        "\n",
        "**Transaction IDs:** It identifies transaction IDs, typically numeric sequences of 10 digits or more.\n",
        "\n",
        "**Data Organization:** Extracted data is stored in a pandas DataFrame, which allows for easy manipulation and analysis.\n",
        "\n",
        "**Output:** The processed data is saved into an Excel file (test3_extracted_text_final_v7.xlsx), preserving the structure and details extracted from the PDF.\n",
        "\n",
        "##Usage:\n",
        "Ensure Python environment has necessary libraries installed: fitz, pandas, and re.\n",
        "\n",
        "Replace pdf_path variable with the path to your PDF file.\n",
        "\n",
        "Run the script to extract data.\n",
        "\n",
        "Check the generated Excel file for extracted and organized data (test3_extracted_text_final_v7.xlsx).\n",
        "\n",
        "##Notes:\n",
        "Ensure the PDF file is accessible and correctly specified in pdf_path.\n",
        "\n",
        "The script uses regular expressions to handle varying formats of data entries (amounts, dates, transaction IDs, etc.).\n",
        "\n",
        "Adjustments may be needed based on specific PDF formats and data extraction requirements."
      ],
      "metadata": {
        "id": "XvZcRDu1n09n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xun0dFI2lj8X",
        "outputId": "5f58d633-5cfe-4751-c7d8-95df154fdc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted and refined text saved to 'test3_extracted_text_final_v7.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF for PDF handling\n",
        "import pandas as pd\n",
        "import re  # Regular Expression module for pattern matching\n",
        "\n",
        "# Replace with your actual PDF path\n",
        "pdf_path = '/content/drive/MyDrive/HACKATHON/test3.pdf'\n",
        "\n",
        "# Function to extract amounts with decimals and commas from a line\n",
        "def extract_amount(line):\n",
        "    # Regular expression pattern to match amounts with decimals and commas\n",
        "    pattern = r'\\b\\d{1,3}(?:,?\\d{3})*(?:\\.\\d{1,2})\\b'\n",
        "    amounts = re.findall(pattern, line)\n",
        "    return amounts\n",
        "\n",
        "# Function to extract amounts with \"Dr\" from a line\n",
        "def extract_dr_amount(line):\n",
        "    # Regular expression pattern to match amounts with \"Dr\" and decimals and commas\n",
        "    pattern = r'\\b\\d{1,3}(?:,?\\d{3})*(?:\\.\\d{1,2})Dr\\b'\n",
        "    dr_amounts = re.findall(pattern, line)\n",
        "    return dr_amounts\n",
        "\n",
        "# Function to extract \"C\" or \"T\" from a line\n",
        "def extract_transaction_type(line):\n",
        "    # Regular expression pattern to match \"C\" or \"T\"\n",
        "    pattern = r'\\b[C|T]\\b'\n",
        "    types = re.findall(pattern, line)\n",
        "    return types\n",
        "\n",
        "# Function to extract text after \"C\" or \"T\" from a line\n",
        "def extract_text_after_ct(line):\n",
        "    # Regular expression pattern to match text after \"C\" or \"T\"\n",
        "    pattern = r'\\b[C|T]\\s+(.+)$'\n",
        "    matches = re.findall(pattern, line)\n",
        "    if matches:\n",
        "        return matches[0].strip()\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "# Initialize variables to store data\n",
        "data = {\n",
        "    'Field': [],\n",
        "    'Value': [],\n",
        "    'Amount': [],\n",
        "    'Amount with Dr': [],\n",
        "    'Transaction Type': [],\n",
        "    'Text after CT': [],\n",
        "    'Important Dates': [],\n",
        "    'Transaction ID': []\n",
        "}\n",
        "\n",
        "# Iterate through all the pages and extract text\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document.load_page(page_num)\n",
        "    text = page.get_text()\n",
        "\n",
        "    # Split text by new lines to handle multiline fields\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        # Ignore empty lines\n",
        "        if line.strip() == '':\n",
        "            continue\n",
        "\n",
        "        # Try splitting by ':' to separate field and value\n",
        "        if ':' in line:\n",
        "            parts = line.split(':', 1)\n",
        "            field = parts[0].strip()\n",
        "            value = parts[1].strip()\n",
        "        else:\n",
        "            # If no ':', treat the entire line as the field (for multiline values)\n",
        "            field = ''\n",
        "            value = line.strip()\n",
        "\n",
        "        # Extract amounts and amounts with \"Dr\" from both field and value\n",
        "        amounts_field = extract_amount(field)\n",
        "        amounts_value = extract_amount(value)\n",
        "        dr_amounts_field = extract_dr_amount(field)\n",
        "        dr_amounts_value = extract_dr_amount(value)\n",
        "\n",
        "        # Combine extracted values while ensuring no duplicates\n",
        "        amounts = list(set(amounts_field + amounts_value))\n",
        "        dr_amounts = list(set(dr_amounts_field + dr_amounts_value))\n",
        "\n",
        "        # Extract transaction type (C or T) from both field and value\n",
        "        transaction_types_field = extract_transaction_type(field)\n",
        "        transaction_types_value = extract_transaction_type(value)\n",
        "\n",
        "        # Combine extracted types while ensuring no duplicates\n",
        "        transaction_types = list(set(transaction_types_field + transaction_types_value))\n",
        "\n",
        "        # Extract text after \"C\" or \"T\"\n",
        "        text_after_ct = extract_text_after_ct(value)\n",
        "\n",
        "        # Extract dates and transaction IDs from both field and value\n",
        "        dates_field = re.findall(r'\\b\\d{2}-[A-Za-z]{3}-\\d{4}\\b', field)\n",
        "        dates_value = re.findall(r'\\b\\d{2}-[A-Za-z]{3}-\\d{4}\\b', value)\n",
        "        transaction_ids_field = re.findall(r'\\b\\d{10,}\\b', field)\n",
        "        transaction_ids_value = re.findall(r'\\b\\d{10,}\\b', value)\n",
        "\n",
        "        # Combine extracted values while ensuring no duplicates\n",
        "        dates = list(set(dates_field + dates_value))\n",
        "        transaction_ids = list(set(transaction_ids_field + transaction_ids_value))\n",
        "\n",
        "        # Append to data dictionary\n",
        "        data['Field'].append(field)\n",
        "        data['Value'].append(value)\n",
        "        data['Amount'].append(\", \".join(amounts))\n",
        "        data['Amount with Dr'].append(\", \".join(dr_amounts))\n",
        "        data['Transaction Type'].append(\", \".join(transaction_types))\n",
        "        data['Text after CT'].append(text_after_ct)\n",
        "        data['Important Dates'].append(\", \".join(dates))\n",
        "        data['Transaction ID'].append(\", \".join(transaction_ids))\n",
        "\n",
        "# Close the PDF document\n",
        "pdf_document.close()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to Excel\n",
        "excel_output_path = 'test3_extracted_text_final_v7.xlsx'\n",
        "df.to_excel(excel_output_path, index=False)\n",
        "\n",
        "print(f\"Extracted and refined text saved to '{excel_output_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auIqljp7mEAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ltoqYFuo44d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code optimised for Test5 File**"
      ],
      "metadata": {
        "id": "m4ibP5FY3QjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview\n",
        "This script extracts specific data from a PDF file and saves it into an Excel file. It uses the PyMuPDF library to read the PDF and regular expressions to parse and extract the required information.\n",
        "\n",
        "##Features\n",
        "Extracts and separates the first two columns from each line in the PDF.\n",
        "Identifies and extracts dates, transaction texts, transaction IDs, and secondary dates from the PDF.\n",
        "Stores the extracted data in a structured format and exports it to an Excel file.\n",
        "##Requirements\n",
        "* PyMuPDF\n",
        "* pandas\n",
        "* re (Regular Expressions module)\n"
      ],
      "metadata": {
        "id": "VXBoAu1P3Vx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Replace with your actual PDF path\n",
        "pdf_path = '/content/drive/MyDrive/HACKATHON/test5.pdf'\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "# Initialize variables to store data\n",
        "data = {\n",
        "    'Column 1': [],\n",
        "    'Column 2': [],\n",
        "    'Date': [],\n",
        "    'Text': [],\n",
        "    'Transaction ID': [],\n",
        "    'Date 2': []\n",
        "}\n",
        "\n",
        "# Regex patterns\n",
        "date_pattern = r'\\d{2}/\\d{2}/\\d{2}'\n",
        "text_pattern = r'[A-Z]+-\\d+-[A-Z\\s\\d]+'\n",
        "transaction_id_pattern = r'\\d{12}'\n",
        "\n",
        "# Iterate through all the pages and extract text\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document.load_page(page_num)\n",
        "    text = page.get_text()\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        if re.search(date_pattern, line):\n",
        "            # Split by spaces and handle each part\n",
        "            parts = line.split()\n",
        "            # Column 1 and Column 2\n",
        "            column_1 = parts[0]\n",
        "            column_2 = parts[1]\n",
        "\n",
        "            # Date, Text, Transaction ID\n",
        "            date_match = re.search(date_pattern, line)\n",
        "            text_match = re.search(text_pattern, line)\n",
        "            transaction_id_match = re.search(transaction_id_pattern, line)\n",
        "\n",
        "            date = date_match.group() if date_match else ''\n",
        "            text = text_match.group() if text_match else ''\n",
        "            transaction_id = transaction_id_match.group() if transaction_id_match else ''\n",
        "\n",
        "            # Date 2\n",
        "            date2_match = re.findall(date_pattern, line)\n",
        "            date2 = date2_match[1] if len(date2_match) > 1 else ''\n",
        "\n",
        "            # Append to data dictionary\n",
        "            data['Column 1'].append(column_1)\n",
        "            data['Column 2'].append(column_2)\n",
        "            data['Date'].append(date)\n",
        "            data['Text'].append(text)\n",
        "            data['Transaction ID'].append(transaction_id)\n",
        "            data['Date 2'].append(date2)\n",
        "\n",
        "# Close the PDF document\n",
        "pdf_document.close()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to Excel\n",
        "excel_output_path = 'test5_extracted_data.xlsx'\n",
        "df.to_excel(excel_output_path, index=False)\n",
        "\n",
        "print(f\"Extracted data saved to '{excel_output_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYyR99ID3Yjb",
        "outputId": "f9ed69ff-bdbe-41eb-c624-d4cc8ec20dc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted data saved to 'test5_extracted_data.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MY5J7xdH3c4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}